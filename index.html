<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning Project Proposal</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; padding: 20px; }
        h1, h2 { color: #333; }
        ul { list-style-type: none; }
        li { margin: 10px 0; }
    </style>
</head>
<body>
    <header>
        <h1>Machine Learning Project Proposal</h1>
    </header>
    
    <section>
        <h2>Introduction/Background</h2>
        <ul>
            <li>✅ Literature Review</li>
            <p>After analyzing existing approaches to this problem, many machine learning algorithms use “EHR” data as the training set. EHR stands for electronic health record, and is a digital store of a patients’ medical history over time. This data is used within and between different hospitals to get the most up to date picture on how a patient is doing. Consequently, all the data which is contained in a dataset containing many EHRs is a viable source of training data for healthcare diagnostics.
              <br/><br/>
              The relevant paper (1) utilize Optum’s EHR database to train their models, with the purpose of predicting risk of lung cancer. This dataset seems to provide a complete time-series data of EHRs, with many different features, such as diagnostics, lab results, immunizations, and prior medical history. Alternate studies done using this dataset is one which aimed to measure and define “post-COVID conditions” (2). 
              <br/><br/>
              While this is a powerful dataset, it is not available for use for free, and we are going to reach out to the Optum team to discuss potential options of working with their dataset or a slice of it.
              <br/><br/>
              Searching for alternatives presented us with MIMIC-IV, another EHR dataset which contains both hospital wide EHR, and ICU specific information (3). This is another candidate for a training data set</p>

            <li>✅ Dataset Description</li>
            <p>In general, our dataset should consist of EHRs. https://ohdsi.github.io/ETL-LambdaBuilder/ consists of the data mapping which another project made using Optum data. From this, we can see many different tables and features we can work with. 
              <br/><br/>
              Things relevant for the purposes of lung cancer detection could be previous diagnoses, death date after lung cancer detection, diet/existing health concerns, and lab data such as blood cell count, immunization, and many more factors. 
              <br/><br/>
              The MIMIC-IV dataset is documented at https://physionet.org/content/mimic-iv-demo/2.2/. This has similar features we could use. Some others in this one include prescriptions, microbiology tables, and lab history. These sets provide a large set of initial training data to work with.</p>
            <li>✅ Dataset Link (if applicable)</li>
            <p>Optum: <a href="https://business.optum.com/en/data-analytics/life-sciences/real-world-data/ehr-data.html">https://business.optum.com/en/data-analytics/life-sciences/real-world-data/ehr-data.html</a></p>
            <p>MIMIC-IV: <a href="https://physionet.org/content/mimiciv/3.1/">https://physionet.org/content/mimiciv/3.1/</a></p>            
        </ul>
    </section>
    
    <section>
        <h2>Problem Definition</h2>
        <ul>
            <li>✅ Problem</li>
            <p>Lung cancer is often diagnosed too late, significantly reducing survival rates. Despite expanded screening guidelines, only 16% of high-risk individuals are screened, and non-smokers remain largely overlooked. Additionally, disparities in treatment and biomarker testing limit access to personalized care, particularly for racial minorities and underserved populations. Existing AI applications focus on tumor detection from imaging rather than proactive risk prediction using electronic health records (EHRs).</p>
            <li>✅ Motivation</li>
            <p>An AI-based lung cancer risk prediction model could help identify high-risk individuals earlier, even before they qualify for screening. By analyzing EHRs, socioeconomic, and environmental factors, AI could uncover hidden risk patterns beyond smoking history, improve screening outreach, and reduce racial and economic disparities. Extending the prediction window beyond the standard 3 years and integrating novel data sources like air pollution exposure could further enhance early detection and intervention strategies.</p>
        </ul>
    </section>
    
    <div class="section">
            <h2>Data Integration and Preprocessing</h2>
            <h3>✅ Data Extraction and Linking</h3>
            <ul>
                <li>Extract Optum EHR data, including demographics, diagnoses, medications, and lab results.</li>
                <li>Incorporate additional variables (possible socioeconomic and environmental datasets):
                    <ul>
                        <li>CDC Social Vulnerability Index (SVI): Measures income, education, and housing quality.</li>
                        <li>American Community Survey (ACS): Provides census-based socioeconomic indicators.</li>
                        <li>EPA Air Quality Data: Includes pollutant levels (PM2.5, NO₂) at ZIP code or county level.</li>
                        <li>NASA/Sentinel-5P: Integrates satellite-based pollution data.</li>
                    </ul>
                </li>
                <li>Link patient ZIP codes with socioeconomic and environmental data, applying imputation for missing values.</li>
            </ul>

            <h3>✅ Data Cleaning and Transformation</h3>
            <ul>
                <li>Impute missing numerical values using <code>SimpleImputer</code> or <code>KNNImputer</code>.</li>
                <li>Handle categorical variables using one-hot or ordinal encoding.</li>
                <li>Detect and process outliers using <code>IsolationForest</code> or IQR-based methods.</li>
                <li>Normalize continuous variables such as air pollution levels for consistency.</li>
            </ul>

            <h3>✅ Feature Engineering</h3>
            <ul>
                <li>Create composite indices for related variables.</li>
                <li>Introduce temporal features to track health and environmental exposure changes.</li>
                <li>Develop interaction terms (e.g., smoking × pollution exposure).</li>
            </ul>
        </div>

        <div class="section">
            <h2>Unsupervised Learning</h2>
            <h3>✅ Clustering (K-Means)</h3>
            <ul>
                <li>Group patients based on clinical, socioeconomic, and environmental factors.</li>
                <li>Identify risk subpopulations for targeted interventions.</li>
            </ul>

            <h3>✅ Dimensionality Reduction (PCA)</h3>
            <ul>
                <li>Apply PCA to reduce feature dimensionality and improve efficiency.</li>
                <li>Mitigate multicollinearity among socioeconomic and environmental features.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Supervised Learning</h2>
            <h3>✅ Model Selection</h3>
            <ul>
                <li>Use Regularized Logistic Regression for interpretability and handling high-dimensional data.</li>
                <li>Apply Ensemble Methods (Random Forest, XGBoost) to capture nonlinear relationships.</li>
            </ul>

            <h3>✅ Model Training and Validation</h3>
            <ul>
                <li>Split data into training and testing sets, using cross-validation where necessary.</li>
                <li>Evaluate models using:
                    <ul>
                        <li>AUC-ROC and Precision-Recall Curves for classification performance.</li>
                        <li>Calibration plots and Brier scores for probability estimation accuracy.</li>
                    </ul>
                </li>
            </ul>

            <h3>✅ Interpretability and Feature Importance</h3>
            <ul>
                <li>Analyze feature importance using tree-based models.</li>
                <li>Use SHAP values for model explainability at both overall and individual levels.</li>
            </ul>
        </div>
    </div>
    
    <section>
        <h2>(Potential) Results and Discussion</h2>
        <ul>
            <li>✅ 3+ Quantitative Metrics</li>
            <li>✅ Project Goals</li>
            <li>✅ Expected Results</li>
        </ul>
    </section>
    
    <section>
        <h2>References</h2>
        <ul>
            <li>✅ 3+ References (IEEE format)</li>
            <p>1. https://pmc.ncbi.nlm.nih.gov/articles/PMC9986687/</p>
            <p>2. https://pmc.ncbi.nlm.nih.gov/articles/PMC10997091/</p>
            <p>3. https://www.nature.com/articles/s41597-022-01899-x</p>
            <li>✅ 1+ In-Text Citation Per Reference</li>
        </ul>
    </section>
    
    <section>
        <h2>Additional Requirements</h2>
        <ul>
            <li>✅ Gantt Chart</li>
            <li>✅ Contribution Table</li>
            <li>✅ Video Presentation</li>
            <li>✅ GitHub Repository</li>
            <li>✅ Project Award Eligibility</li>
        </ul>
    </section>
</body>
</html>
